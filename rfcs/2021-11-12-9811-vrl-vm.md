# RFC 9811 - 2021-11-12 - VRL bytecode VM

This RFC proposes implementing a bytecode VM. VRL will be compiled to the bytecode
and executed by this VM, with the aim to significantly improve the performance of
executing VRL scripts.

## Context

This RFC is a follow on from
[rfcs/2021-10-14-9811-vrl-performance.md](https://github.com/vectordotdev/vector/pull/9812)

## Scope

### In scope

This RFC is purely about developing a bytecode VM for VRL.

### Out of scope

Any other performance issues relating to VRL will be discussed in
[rfcs/2021-10-14-9811-vrl-performance.md](https://github.com/vectordotdev/vector/pull/9812)

## Proposal

### Implementation

Vrl compiles to an AST that is then walked during resolution. Each node in that
tree is boxed and stored in disparate regions of memory. As a result walking
the tree means that the CPU caches must be constantly swapped.

Instead we can create a bytecode VM to store the execution of the Vrl program.

Bytecode is essentially a big enum of instructions (that are represented by an integer
using the [num-derive](https://crates.io/crates/num-derive),
[num-traits](https://crates.io/crates/num-traits) crates):

```rust
#[derive(FromPrimitive, ToPrimitive, Copy, Clone, Debug, PartialEq, Eq)]
pub enum OpCode {
    Return = 255,
    Constant,
    Negate,
    Add,
    Subtract,
    Multiply,
    Divide,
    Print,
    Not,
    Greater,
    GreaterEqual,
    Less,
    LessEqual,
    NotEqual,
    Equal,
    Pop,
    JumpIfFalse,
    Jump,
    SetPath,
    GetPath,
    Call,
    ...
}
```

The Vm is a struct comprising of the following fields:

```rust
#[derive(Clone, Debug, Default)]
pub struct Vm {
    instructions: Vec<usize>,
    constants: Vec<Literal>,
    targets: Vec<Variable>,
    stack: Vec<Value>,
    ip: usize,
}
```

- instructions

The instructions field is a `Vec` of `OpCode` cast to a usize. The reason for
the cast is because not all instructions are `OpCode`. For example the
instructions `[.., Constant, 12, ..]` when evaluated will load the constant
stored in the `values` `Vec` that is found in position 12 onto the stack.

- constants

A list of constant values found in the program. Since the bytecode only
contains integers any actual values must be stored here. This also allows
literals to be deduped.

- targets

A list of paths used in the program, similar to `values`.

- stack

The Vm is a stack based Vm. Every expression that is evaluated pushes the
result on the stack. Every operation pulls the values it uses from the stack.

- ip

The instruction pointer points to the next instruction to evaluate.

With each node of the AST compiled down to just a few bytes and all
instructions held in contiguous memory evaluation of the program should be able
to take full advantage of the CPU cache which should result in much faster
execution.

#### Calling functions

Calling functions in the stdlib will be a case of evaluating each parameter
with the results pushed onto the stack.

Since Vrl allows for named parameters and optional parameters, the compiler
will need to ensure the bytecode evaluates each parameter in the order declared
in the function. Bytecode will need to be emitted for parameters that are not
specified in the Vrl script to add a default value to the stack.

We do not want `stdlib` functions to have access to the VM since that risks a rogue
function destroying the VM's state. To implement the `OpCode::Call` we need
the following steps:

1. Load the parameters from `Function::parameters()`.
2. For each parameter pull a value from the stack pull a value from the stack.
3. Insert the parameter name and this value into a `BTreeMap`.
4. Call the function, passing the `BTreeMap` to the function.
5. Push the value returned from the function onto the stack.

Parameters that have not been specified are represented as `Value::Null`.

### Optimization

With the code as a single dimension array of Bytecode, it could be possible to
scan the code for patterns and reorganise the Bytecode so it can run in a more
optimal way.

A lot more thought and research needs to go into this before we can consider
implementing these changes.

## Drawbacks

Downsides to using a Vm:

- The code is a bit more complex. With an AST that is walked it is fairly apparent
  what the code will be doing at any point. With a Vm, this is not the case, it
  is harder to look at the instructions in the Vm and follow back to what part
  of the VRL code is being evaluated. We will need to write some extensive
  debugging tools to allow for decent introspection into the Vm.

  However, VRL is a very simple language, which does also mean the VM will be
  simple.

- We lose some safety that we get from the Rust compiler. There will need
  to be significant fuzz testing to ensure that the code runs correctly under
  all circumstances. It should be noted however that the entire VM will not
  require any _unsafe_ code.

- Currently each stdlib function is responsible for evaluating their own
  parameters. This allows parameters to be lazily evaluated. Most likely with a
  Vm, the parameters will need to be evaluated up front and the stack passed
  into the function. This could impact performance.

## Prior Art

- GoScript - An implementation of Go using a bytecode Vm,
  https://github.com/oxfeeefeee/goscript

- CPython - https://github.com/python/cpython

## Alternatives

### WASM

Instead of writing our own VM we could transpile VRL code to WASM. WASM is a mature and
performant VM that could give us near native speeds.

The issues with using WASM are that it would require data to be serialized in order
to move between Vector and WASM. This would incur a significant performance penalty.

WASM provides a lot more functionality and complexity than is required for VRL. By
developing our own VM we will be able to customize it purely for the usecase required
by VRL. This allows us to implement very VRL specific OpCodes which should allow the
bytecode stay simple.

### Represent additional data in the OpCode

The current suggestion represents each OpCode as a single instruction in the instruction list. An
OpCode with it's data occupies two instructions.

For example, with the current suggestion to load a constant three things have to happen:

1. Add the Constant OpCode to the instructions.
2. Add the actual constant value to the list of constants.
3. Add the index of the constant in the constant list to the list of constants.

#### Include value in the OpCode

These three things could be represented as a single instruction if we included the constant
value in the OpCode:

```rust
enum OpCode {
    ...
    Constant(Box<Value>)
    ...
}
```

This will increase `size_of::<OpCode>` from 8 to 16, potentially doubling the memory size of the instruction
list.

It also means we do not need to store a separate list of constants. On the plus side, this is one less lookup
at runtime to load the constant. On the down side, we wouldn't be able to dedupe the constant, so for example,
if the code uses the same string twice, it would be represented twice in the bytecode.

#### Bitmap the OpCode data

Since we will never have `usize` OpCodes, or `usize` constants in our constant list, we could potentially
combine these two values into a single `usize` and bitmask each part.

```rust
OpCode = FromPrimitive::from_usize(instruction && (1_usize << (usize::BITS / 2)) - 1 << (usize::BITS / 2)))
data = instruction && (1_usize << (usize::BITS / 2)) - 1
```

## Outstanding Questions

1. Is it sufficient to represent an empty optional parameter as `Value::Null`. If not, we will need to represent
   values on the stack with a type that wraps `Value`. eg. `Option<Value>`.

## Plan Of Attack

- [ ] Submit a PR with spike-level code _roughly_ demonstrating the change for
      the VM. [here](https://github.com/vectordotdev/vector/pull/9829)
- [ ] Implement the VM and the VRL to VM compiler.
- [ ] Test. We will be able to run both the VM and the Expression walker simultaneously
      which will allow us to ensure we still get the same results.
